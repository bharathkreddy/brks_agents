{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "786c3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b624a621",
   "metadata": {},
   "source": [
    "### Using local models - ollama\n",
    "Run `ollama run deepseek-r1:8b` locally on terminal before doing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fafcef53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Greetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"deepseek-r1:8b\"\n",
    "ollama_model = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "response = ollama_model.chat.completions.create(\n",
    " model=MODEL,\n",
    " messages=[{\"role\": \"user\", \"content\": \"who are you ?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ada5a",
   "metadata": {},
   "source": [
    "### OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bdf2ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! Welcome, and thanks for saying hi. I’m ChatGPT—here to help answer questions, brainstorm ideas, or just chat. What can I do for you today?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o4-mini\",\n",
    "    messages=[{\"role\":\"user\", \"content\":message}]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133c6da",
   "metadata": {},
   "source": [
    "### AI web summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "431a333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some websites need a proper header when fetching them, below header is copied from dev tools under request headers\n",
    "# BeautifulSoup is ideal for static pages and simple scraping tasks, offering speed and efficiency. Selenium is better for dynamic content or tasks requiring user interaction, like form submission or clicking buttons.\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using BeautifulSoupe Library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelavent in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelavent.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        self.soup = soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77580e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bharath Reddy - Northern Trust | LinkedIn\n",
      "LinkedIn and 3rd parties use essential and non-essential cookies to provide, secure, analyze and improve our Services, and to show you relevant ads (including\n",
      "professional and job ads\n",
      ") on and off LinkedIn. Learn more in our\n",
      "Cookie Policy\n",
      ".\n",
      "Select Accept to consent or Reject to decline non-essential cookies for this use. You can update your choices at any time in your\n",
      "settings\n",
      ".\n",
      "Accept\n",
      "Reject\n",
      "Skip to main content\n",
      "LinkedIn\n",
      "Top Content\n",
      "People\n",
      "Learning\n",
      "Jobs\n",
      "Games\n",
      "Get the app\n",
      "Join now\n",
      "Sign in\n",
      "Sign in to view Bharath’s full profile\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "Bharath Reddy\n",
      "Sign in to view Bharath’s full profile\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "London Area, United Kingdom\n",
      "Contact Info\n",
      "Sign in to view Bharath’s full profile\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "18K followers\n",
      "500+ connections\n",
      "See your mutual connections\n",
      "View mutual connections with Bharath\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "Join to view profile\n",
      "Message\n",
      "Sign in to view Bharath’s full profile\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "Northern Trust\n",
      "Caltech\n",
      "Personal Website\n",
      "Report this profile\n",
      "About\n",
      "I use data and quantitative methods to solve business problems. My expertise is at the…\n",
      "see more\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "Activity\n",
      "Follow\n",
      "Sign in to view Bharath’s full profile\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "### 🧠 **10 Cutting-Edge Knowledge Graph Architectures (2025)**  \n",
      "\n",
      "1️⃣ **Domain Knowledge Graphs**  \n",
      "- **Architecture:** Industry-specific ontologies…\n",
      "### 🧠 **10 Cutting-Edge Knowledge Graph Architectures (2025)**  \n",
      "\n",
      "1️⃣ **Domain Knowledge Graphs**  \n",
      "- **Architecture:** Industry-specific ontologies…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "Fine-tuning massive LLMs used to be painfully slow, but not anymore!\n",
      "\n",
      "4 open source libraries that accelerate fine-tuning of Large Language…\n",
      "Fine-tuning massive LLMs used to be painfully slow, but not anymore!\n",
      "\n",
      "4 open source libraries that accelerate fine-tuning of Large Language…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "🚨🚨🚨Breaking!!! Today, Anthropic officially launched Claude for Financial Services!!\n",
      "\n",
      "This is a powerful, enterprise‑grade AI tailored for banks…\n",
      "🚨🚨🚨Breaking!!! Today, Anthropic officially launched Claude for Financial Services!!\n",
      "\n",
      "This is a powerful, enterprise‑grade AI tailored for banks…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "Join now to see all activity\n",
      "Experience & Education\n",
      "Northern Trust\n",
      "****** **** *********\n",
      "***.*************.***\n",
      "*******\n",
      "******** ***** ***********\n",
      "**** ******* **** *********\n",
      "*******\n",
      "**** ******** ******* ** ****** ******\n",
      "2021\n",
      "-\n",
      "2022\n",
      "*** ********** ** ***** ** ******\n",
      "************ ****** **** ******** ******* ** ********** ************ *** ******* ******** *\n",
      "2020\n",
      "-\n",
      "2021\n",
      "View Bharath’s full experience\n",
      "See their title, tenure and more.\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "Licenses & Certifications\n",
      "Getting and Cleaning Data\n",
      "Johns Hopkins University Data Science Laboratory\n",
      "Issued\n",
      "Apr 2019\n",
      "Credential ID FSSCJXHKRZNH\n",
      "See credential\n",
      "Practical Machine Learning\n",
      "Johns Hopkins University Data Science Laboratory\n",
      "Issued\n",
      "Apr 2019\n",
      "Credential ID 8DLEC4UXVSU3\n",
      "See credential\n",
      "R Programming\n",
      "Coursera Course Certificates\n",
      "Issued\n",
      "Apr 2019\n",
      "Credential ID YWC3YN49ZJPW\n",
      "See credential\n",
      "Regression Models\n",
      "Coursera Course Certificates\n",
      "Issued\n",
      "Apr 2019\n",
      "Credential ID 42JEBPMPPYAP\n",
      "See credential\n",
      "The R Programming Environment\n",
      "Coursera Course Certificates\n",
      "Issued\n",
      "Apr 2019\n",
      "Credential ID G8DPE9UFGVG3\n",
      "See credential\n",
      "Reproducible Research\n",
      "Johns Hopkins University Data Science Laboratory\n",
      "Issued\n",
      "Mar 2019\n",
      "Credential ID LXYT3DLLWYA5\n",
      "See credential\n",
      "Fundamentals of Visualization with Tableau\n",
      "Coursera Course Certificates\n",
      "Issued\n",
      "Mar 2019\n",
      "Credential ID B3NEY6AZDLHP\n",
      "See credential\n",
      "The Data Scientist’s Toolbox\n",
      "Johns Hopkins University Advanced Academic Programs\n",
      "Issued\n",
      "Mar 2019\n",
      "Credential ID SV3EAFUML88E\n",
      "See credential\n",
      "Statistical Inference\n",
      "Coursera Course Certificates\n",
      "Issued\n",
      "Feb 2019\n",
      "Credential ID LT9ANA6B3PMW\n",
      "See credential\n",
      "Business Metrics for Data-Driven Companies\n",
      "Duke University\n",
      "Issued\n",
      "Mar 2018\n",
      "Credential ID 6H8T6MTYX7KW\n",
      "See credential\n",
      "Join now to see all certifications\n",
      "Recommendations received\n",
      "Sushant Chatterjee\n",
      "“Bharat has always been a fantastic resource, a keen intellectual, and a terrific individual who thinks out of box. During college, I noticed the way how he will add resources and find links for whichever projects given to him with elan and ease! He combines rich literary words along with strong analytical / mathematical researches - a rare combination :) He always flourish under challenges, and apart from excelling in academics - than man also possesses a nice human heart and friendly banter. A strong people's manager, I wish him lot of success in his career and life.”\n",
      "1 person has recommended Bharath\n",
      "Join now to view\n",
      "More activity by Bharath\n",
      "If you're a software engineer who want to get better at algorithms and system design, read these 12 curated articles: \n",
      "\n",
      "1. What every engineer should…\n",
      "If you're a software engineer who want to get better at algorithms and system design, read these 12 curated articles: \n",
      "\n",
      "1. What every engineer should…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "If you want to improve your coding skills, check these 5 GitHub repos: \n",
      "\n",
      "1. Awesome Software and Architectural Design Patterns\n",
      "\n",
      "A curated list of…\n",
      "If you want to improve your coding skills, check these 5 GitHub repos: \n",
      "\n",
      "1. Awesome Software and Architectural Design Patterns\n",
      "\n",
      "A curated list of…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "What if I told you that you could slash your multi-vector embedding costs by 70%?\n",
      "(and still maintain solid performance?)\n",
      "\n",
      "Multi-vector models like…\n",
      "What if I told you that you could slash your multi-vector embedding costs by 70%?\n",
      "(and still maintain solid performance?)\n",
      "\n",
      "Multi-vector models like…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "If you want to become a top-tier software developer, read these 10 books:\n",
      "\n",
      "1. The Pragmatic Programmer by Andrew Hunt and David Thomas \n",
      "\n",
      "It'll teach…\n",
      "If you want to become a top-tier software developer, read these 10 books:\n",
      "\n",
      "1. The Pragmatic Programmer by Andrew Hunt and David Thomas \n",
      "\n",
      "It'll teach…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "These Leetcode blogs will tell you every pattern & tactic you need to know to solve Leetcode problems. If you don't want to solve 500+ Leetcode…\n",
      "These Leetcode blogs will tell you every pattern & tactic you need to know to solve Leetcode problems. If you don't want to solve 500+ Leetcode…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "This is hands down the best playlist I found for Deep Learning \n",
      "\n",
      "This is taught by Prof. Bryce, the GOAT in his field.\n",
      "\n",
      "I've put together the list of…\n",
      "This is hands down the best playlist I found for Deep Learning \n",
      "\n",
      "This is taught by Prof. Bryce, the GOAT in his field.\n",
      "\n",
      "I've put together the list of…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "If I had to go from zero to building reliable agentic systems in 90 days, this is the exact learning arc I’d follow.\n",
      "\n",
      "You don’t “learn AI.” You build…\n",
      "If I had to go from zero to building reliable agentic systems in 90 days, this is the exact learning arc I’d follow.\n",
      "\n",
      "You don’t “learn AI.” You build…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "Last year I wrote seven tutorials on infinite-width networks for RBC Borealis:\n",
      "\n",
      "https://lnkd.in/eEmBJRhV\n",
      "\n",
      "Parts I-III discuss the Neural Tangent…\n",
      "Last year I wrote seven tutorials on infinite-width networks for RBC Borealis:\n",
      "\n",
      "https://lnkd.in/eEmBJRhV\n",
      "\n",
      "Parts I-III discuss the Neural Tangent…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "12 Blogs That Changed How I Think About LLMs & RAG  \n",
      "\n",
      "Six months into working with LLMs, I hit the ceiling. Tutorials felt shallow. Docs were too…\n",
      "12 Blogs That Changed How I Think About LLMs & RAG  \n",
      "\n",
      "Six months into working with LLMs, I hit the ceiling. Tutorials felt shallow. Docs were too…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "𝗧𝗶𝗺𝗲 𝗦𝗲𝗿𝗶𝗲𝘀 𝗙𝗼𝗿𝗲𝗰𝗮𝘀𝘁𝗶𝗻𝗴 𝘄𝗶𝘁𝗵 𝗗𝗲𝗲𝗽 𝗟𝗲𝗮𝗿𝗻𝗶𝗻𝗴!💡📈\n",
      "In recent years, deep learning has been widely used for time…\n",
      "𝗧𝗶𝗺𝗲 𝗦𝗲𝗿𝗶𝗲𝘀 𝗙𝗼𝗿𝗲𝗰𝗮𝘀𝘁𝗶𝗻𝗴 𝘄𝗶𝘁𝗵 𝗗𝗲𝗲𝗽 𝗟𝗲𝗮𝗿𝗻𝗶𝗻𝗴!💡📈\n",
      "In recent years, deep learning has been widely used for time…\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "This is a great strategy 🤩\n",
      "This is a great strategy 🤩\n",
      "Liked by\n",
      "Bharath Reddy\n",
      "View Bharath’s full profile\n",
      "See who you know in common\n",
      "Get introduced\n",
      "Contact Bharath directly\n",
      "Join to view full profile\n",
      "Sign in\n",
      "Stay updated on your professional world\n",
      "Sign in\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "Other similar profiles\n",
      "Josly Dhanraj Fernandes\n",
      "Second Vice President, Senior Consultant at Northern Trust Corporation\n",
      "Bengaluru\n",
      "Connect\n",
      "Madhan MV\n",
      "Actively Looking for Employment | Experienced Writer with more than 9 Years of experience | Content Writing | Technical Writing | Creative Writing | Blogs | Articles | Web Content | Research Papers\n",
      "Bengaluru\n",
      "Connect\n",
      "Rabia Ahmad\n",
      "IIM Nagpur | Prince2 Agile| Data Quality| Compliance| Payments\n",
      "Bengaluru\n",
      "Connect\n",
      "Kshitij Singh\n",
      "Mumbai\n",
      "Connect\n",
      "Javeed Nadaf\n",
      "Vice President II | Lead Manager Middle Office Corporate Action and Client Service Delivery at BNY International Operations (India) Private Ltd.\n",
      "Pune\n",
      "Connect\n",
      "Nithin M\n",
      "Officer, Team Leader | Global Derivatives Practice | Collateral Management | Leadership\n",
      "Bengaluru\n",
      "Connect\n",
      "Naveen Sai P\n",
      "Mumbai\n",
      "Connect\n",
      "Atul Sashittal\n",
      "Mumbai Metropolitan Region\n",
      "Connect\n",
      "Ranjeetha Rao\n",
      "Assistant Vice President in Hedge Fund Accounting  at Statestreet Corporation\n",
      "Bengaluru\n",
      "Connect\n",
      "Explore top content on LinkedIn\n",
      "Find curated posts and insights for relevant topics all in one place.\n",
      "View top content\n",
      "Others named\n",
      "Bharath Reddy\n",
      "in\n",
      "United Kingdom\n",
      "Bharath Reddy\n",
      "London\n",
      "Bharath Reddy\n",
      "Data Engineer | Pyspark | Databricks | Cloud, BI, ETL Expert\n",
      "United Kingdom\n",
      "Bharath reddy\n",
      "London Area, United Kingdom\n",
      "Bharath Reddy\n",
      "Civil Engineer | MSc Construction Project & Cost Management | Temporary Works | Tunnels | HS2\n",
      "United Kingdom\n",
      "29 others named Bharath Reddy in United Kingdom are on LinkedIn\n",
      "See others named\n",
      "Bharath Reddy\n",
      "Add new skills with these courses\n",
      "2h 45m\n",
      "Learning Data Science\n",
      "3h 8m\n",
      "Build a No-Code ETL Pipeline with Google BigQuery\n",
      "2h 29m\n",
      "Big Data in the Age of AI\n",
      "See all courses\n",
      "LinkedIn\n",
      "© 2025\n",
      "About\n",
      "Accessibility\n",
      "User Agreement\n",
      "Privacy Policy\n",
      "Cookie Policy\n",
      "Copyright Policy\n",
      "Brand Policy\n",
      "Guest Controls\n",
      "Community Guidelines\n",
      "العربية (Arabic)\n",
      "বাংলা (Bangla)\n",
      "Čeština (Czech)\n",
      "Dansk (Danish)\n",
      "Deutsch (German)\n",
      "Ελληνικά (Greek)\n",
      "English (English)\n",
      "Español (Spanish)\n",
      "فارسی (Persian)\n",
      "Suomi (Finnish)\n",
      "Français (French)\n",
      "हिंदी (Hindi)\n",
      "Magyar (Hungarian)\n",
      "Bahasa Indonesia (Indonesian)\n",
      "Italiano (Italian)\n",
      "עברית (Hebrew)\n",
      "日本語 (Japanese)\n",
      "한국어 (Korean)\n",
      "मराठी (Marathi)\n",
      "Bahasa Malaysia (Malay)\n",
      "Nederlands (Dutch)\n",
      "Norsk (Norwegian)\n",
      "ਪੰਜਾਬੀ (Punjabi)\n",
      "Polski (Polish)\n",
      "Português (Portuguese)\n",
      "Română (Romanian)\n",
      "Русский (Russian)\n",
      "Svenska (Swedish)\n",
      "తెలుగు (Telugu)\n",
      "ภาษาไทย (Thai)\n",
      "Tagalog (Tagalog)\n",
      "Türkçe (Turkish)\n",
      "Українська (Ukrainian)\n",
      "Tiếng Việt (Vietnamese)\n",
      "简体中文 (Chinese (Simplified))\n",
      "正體中文 (Chinese (Traditional))\n",
      "Language\n",
      "Agree & Join LinkedIn\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "View Bharath’s full profile\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "LinkedIn\n",
      "LinkedIn is better on the app\n",
      "Don’t have the app? Get it in the Microsoft Store.\n",
      "Open the app\n"
     ]
    }
   ],
   "source": [
    "brk = Website(\"https://www.linkedin.com/in/bharath-k-reddy/\")\n",
    "print(brk.title)\n",
    "print(brk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4602b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyses the contents of a website \\\n",
    "    and provides a short summary, ignoring text that might be navigation related. \\\n",
    "    Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "361b2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled: {website.title}\"\n",
    "    user_prompt += \"The contents of this website is as follows; \\\n",
    "        please provide a short summary of this website in markdown.\\\n",
    "        if it includes news or announcements, then summarize these too. \\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acaf5c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are looking at a website titled: How we built our multi-agent research system \\\\ AnthropicThe contents of this website is as follows;         please provide a short summary of this website in markdown.        if it includes news or announcements, then summarize these too. \\n\\nSkip to main content\\nSkip to footer\\nClaude\\nAPI\\nSolutions\\nResearch\\nCommitments\\nLearn\\nNews\\nTry Claude\\nEngineering at Anthropic\\nHow we built our multi-agent research system\\nPublished\\nJun 13, 2025\\nOur Research feature uses multiple Claude agents to explore complex topics more effectively. We share the engineering challenges and the lessons we learned from building this system.\\nClaude now has\\nResearch capabilities\\nthat allow it to search across the web, Google Workspace, and any integrations to accomplish complex tasks.\\nThe journey of this multi-agent system from prototype to production taught us critical lessons about system architecture, tool design, and prompt engineering. A multi-agent system consists of multiple agents (LLMs autonomously using tools in a loop) working together. Our Research feature involves an agent that plans a research process based on user queries, and then uses tools to create parallel agents that search for information simultaneously. Systems with multiple agents introduce new challenges in agent coordination, evaluation, and reliability.\\nThis post breaks down the principles that worked for us—we hope you'll find them useful to apply when building your own multi-agent systems.\\nBenefits of a multi-agent system\\nResearch work involves open-ended problems where it’s very difficult to predict the required steps in advance. You can’t hardcode a fixed path for exploring complex topics, as the process is inherently dynamic and path-dependent. When people conduct research, they tend to continuously update their approach based on discoveries, following leads that emerge during investigation.\\nThis unpredictability makes AI agents particularly well-suited for research tasks. Research demands the flexibility to pivot or explore tangential connections as the investigation unfolds. The model must operate autonomously for many turns, making decisions about which directions to pursue based on intermediate findings. A linear, one-shot pipeline cannot handle these tasks.\\nThe essence of search is compression: distilling insights from a vast corpus. Subagents facilitate compression by operating in parallel with their own context windows, exploring different aspects of the question simultaneously before condensing the most important tokens for the lead research agent. Each subagent also provides separation of concerns—distinct tools, prompts, and exploration trajectories—which reduces path dependency and enables thorough, independent investigations.\\nOnce intelligence reaches a threshold, multi-agent systems become a vital way to scale performance. For instance, although individual humans have become more intelligent in the last 100,000 years, human societies have become\\nexponentially\\nmore capable in the information age because of our\\ncollective\\nintelligence and ability to coordinate. Even generally-intelligent agents face limits when operating as individuals; groups of agents can accomplish far more.\\nOur internal evaluations show that multi-agent research systems excel especially for breadth-first queries that involve pursuing multiple independent directions simultaneously. We found that a multi-agent system with Claude Opus 4 as the lead agent and Claude Sonnet 4 subagents outperformed single-agent Claude Opus 4 by 90.2% on our internal research eval. For example, when asked to identify all the board members of the companies in the Information Technology S&P 500, the multi-agent system found the correct answers by decomposing this into tasks for subagents, while the single agent system failed to find the answer with slow, sequential searches.\\nMulti-agent systems work mainly because they help spend enough tokens to solve the problem. In our analysis, three factors explained 95% of the performance variance in the\\nBrowseComp\\nevaluation (which tests the ability of browsing agents to locate hard-to-find information). We found that token usage by itself explains 80% of the variance, with the number of tool calls and the model choice as the two other explanatory factors. This finding validates our architecture that distributes work across agents with separate context windows to add more capacity for parallel reasoning. The latest Claude models act as large efficiency multipliers on token use, as upgrading to Claude Sonnet 4 is a larger performance gain than doubling the token budget on Claude Sonnet 3.7. Multi-agent architectures effectively scale token usage for tasks that exceed the limits of single agents.\\nThere is a downside: in practice, these architectures burn through tokens fast. In our data, agents typically use about 4× more tokens than chat interactions, and multi-agent systems use about 15× more tokens than chats. For economic viability, multi-agent systems require tasks where the value of the task is high enough to pay for the increased performance. Further, some domains that require all agents to share the same context or involve many dependencies between agents are not a good fit for multi-agent systems today. For instance, most coding tasks involve fewer truly parallelizable tasks than research, and LLM agents are not yet great at coordinating and delegating to other agents in real time. We’ve found that multi-agent systems excel at valuable tasks that involve heavy parallelization, information that exceeds single context windows, and interfacing with numerous complex tools.\\nArchitecture overview for Research\\nOur Research system uses a multi-agent architecture with an orchestrator-worker pattern, where a lead agent coordinates the process while delegating to specialized subagents that operate in parallel.\\nThe multi-agent architecture in action: user queries flow through a lead agent that creates specialized subagents to search for different aspects in parallel.\\nWhen a user submits a query, the lead agent analyzes it, develops a strategy, and spawns subagents to explore different aspects simultaneously. As shown in the diagram above, the subagents act as intelligent filters by iteratively using search tools to gather information, in this case on AI agent companies in 2025, and then returning a list of companies to the lead agent so it can compile a final answer.\\nTraditional approaches using Retrieval Augmented Generation (RAG) use static retrieval. That is, they fetch some set of chunks that are most similar to an input query and use these chunks to generate a response. In contrast, our architecture uses a multi-step search that dynamically finds relevant information, adapts to new findings, and analyzes results to formulate high-quality answers.\\nProcess diagram showing the complete workflow of our multi-agent Research system. When a user submits a query, the system creates a LeadResearcher agent that enters an iterative research process. The LeadResearcher begins by thinking through the approach and saving its plan to Memory to persist the context, since if the context window exceeds 200,000 tokens it will be truncated and it is important to retain the plan. It then creates specialized Subagents (two are shown here, but it can be any number) with specific research tasks. Each Subagent independently performs web searches, evaluates tool results using\\ninterleaved thinking\\n, and returns findings to the LeadResearcher. The LeadResearcher synthesizes these results and decides whether more research is needed—if so, it can create additional subagents or refine its strategy. Once sufficient information is gathered, the system exits the research loop and passes all findings to a CitationAgent, which processes the documents and research report to identify specific locations for citations. This ensures all claims are properly attributed to their sources. The final research results, complete with citations, are then returned to the user.\\nPrompt engineering and evaluations for research agents\\nMulti-agent systems have key differences from single-agent systems, including a rapid growth in coordination complexity. Early agents made errors like spawning 50 subagents for simple queries, scouring the web endlessly for nonexistent sources, and distracting each other with excessive updates. Since each agent is steered by a prompt, prompt engineering was our primary lever for improving these behaviors. Below are some principles we learned for prompting agents:\\nThink like your agents.\\nTo iterate on prompts, you must understand their effects. To help us do this, we built simulations using our\\nConsole\\nwith the exact prompts and tools from our system, then watched agents work step-by-step. This immediately revealed failure modes: agents continuing when they already had sufficient results, using overly verbose search queries, or selecting incorrect tools. Effective prompting relies on developing an accurate mental model of the agent, which can make the most impactful changes obvious.\\nTeach the orchestrator how to delegate.\\nIn our system, the lead agent decomposes queries into subtasks and describes them to subagents. Each subagent needs an objective, an output format, guidance on the tools and sources to use, and clear task boundaries. Without detailed task descriptions, agents duplicate work, leave gaps, or fail to find necessary information. We started by allowing the lead agent to give simple, short instructions like 'research the semiconductor shortage,' but found these instructions often were vague enough that subagents misinterpreted the task or performed the exact same searches as other agents. For instance, one subagent explored the 2021 automotive chip crisis while 2 others duplicated work investigating current 2025 supply chains, without an effective division of labor.\\nScale effort to query complexity.\\nAgents struggle to judge appropriate effort for different tasks, so we embedded scaling rules in the prompts. Simple fact-finding requires just 1 agent with 3-10 tool calls, direct comparisons might need 2-4 subagents with 10-15 calls each, and complex research might use more than 10 subagents with clearly divided responsibilities. These explicit guidelines help the lead agent allocate resources efficiently and prevent overinvestment in simple queries, which was a common failure mode in our early versions.\\nTool design and selection are critical.\\nAgent-tool interfaces are as critical as human-computer interfaces. Using the right tool is efficient—often, it’s strictly necessary. For instance, an agent searching the web for context that only exists in Slack is doomed from the start. With\\nMCP servers\\nthat give the model access to external tools, this problem compounds, as agents encounter unseen tools with descriptions of wildly varying quality. We gave our agents explicit heuristics: for example, examine all available tools first, match tool usage to user intent, search the web for broad external exploration, or prefer specialized tools over generic ones. Bad tool descriptions can send agents down completely wrong paths, so each tool needs a distinct purpose and a clear description.\\nLet agents improve themselves\\n. We found that the Claude 4 models can be excellent prompt engineers. When given a prompt and a failure mode, they are able to diagnose why the agent is failing and suggest improvements. We even created a tool-testing agent—when given a flawed MCP tool, it attempts to use the tool and then rewrites the tool description to avoid failures. By testing the tool dozens of times, this agent found key nuances and bugs. This process for improving tool ergonomics resulted in a 40% decrease in task completion time for future agents using the new description, because they were able to avoid most mistakes.\\nStart wide, then narrow down.\\nSearch strategy should mirror expert human research: explore the landscape before drilling into specifics. Agents often default to overly long, specific queries that return few results. We counteracted this tendency by prompting agents to start with short, broad queries, evaluate what’s available, then progressively narrow focus.\\nGuide the thinking process.\\nExtended thinking mode\\n, which leads Claude to output additional tokens in a visible thinking process, can serve as a controllable scratchpad. The lead agent uses thinking to plan its approach, assessing which tools fit the task, determining query complexity and subagent count, and defining each subagent’s role. Our testing showed that extended thinking improved instruction-following, reasoning, and efficiency. Subagents also plan, then use\\ninterleaved thinking\\nafter tool results to evaluate quality, identify gaps, and refine their next query. This makes subagents more effective in adapting to any task.\\nParallel tool calling transforms speed and performance.\\nComplex research tasks naturally involve exploring many sources. Our early agents executed sequential searches, which was painfully slow. For speed, we introduced two kinds of parallelization: (1) the lead agent spins up 3-5 subagents in parallel rather than serially; (2) the subagents use 3+ tools in parallel. These changes cut research time by up to 90% for complex queries, allowing Research to do more work in minutes instead of hours while covering more information than other systems.\\nOur prompting strategy focuses on instilling good heuristics rather than rigid rules. We studied how skilled humans approach research tasks and encoded these strategies in our prompts—strategies like decomposing difficult questions into smaller tasks, carefully evaluating the quality of sources, adjusting search approaches based on new information, and recognizing when to focus on depth (investigating one topic in detail) vs. breadth (exploring many topics in parallel). We also proactively mitigated unintended side effects by setting explicit guardrails to prevent the agents from spiraling out of control. Finally, we focused on a fast iteration loop with observability and test cases.\\nEffective evaluation of agents\\nGood evaluations are essential for building reliable AI applications, and agents are no different. However, evaluating multi-agent systems presents unique challenges. Traditional evaluations often assume that the AI follows the same steps each time: given input X, the system should follow path Y to produce output Z. But multi-agent systems don't work this way. Even with identical starting points, agents might take completely different valid paths to reach their goal. One agent might search three sources while another searches ten, or they might use different tools to find the same answer. Because we don’t always know what the right steps are, we usually can't just check if agents followed the “correct” steps we prescribed in advance. Instead, we need flexible evaluation methods that judge whether agents achieved the right outcomes while also following a reasonable process.\\nStart evaluating immediately with small samples\\n. In early agent development, changes tend to have dramatic impacts because there is abundant low-hanging fruit. A prompt tweak might boost success rates from 30% to 80%. With effect sizes this large, you can spot changes with just a few test cases. We started with a set of about 20 queries representing real usage patterns. Testing these queries often allowed us to clearly see the impact of changes. We often hear that AI developer teams delay creating evals because they believe that only large evals with hundreds of test cases are useful. However, it’s best to start with small-scale testing right away with a few examples, rather than delaying until you can build more thorough evals.\\nLLM-as-judge evaluation scales when done well.\\nResearch outputs are difficult to evaluate programmatically, since they are free-form text and rarely have a single correct answer. LLMs are a natural fit for grading outputs. We used an LLM judge that evaluated each output against criteria in a rubric: factual accuracy (do claims match sources?), citation accuracy (do the cited sources match the claims?), completeness (are all requested aspects covered?), source quality (did it use primary sources over lower-quality secondary sources?), and tool efficiency (did it use the right tools a reasonable number of times?). We experimented with multiple judges to evaluate each component, but found that a single LLM call with a single prompt outputting scores from 0.0-1.0 and a pass-fail grade was the most consistent and aligned with human judgements. This method was especially effective when the eval test cases\\ndid\\nhave a clear answer, and we could use the LLM judge to simply check if the answer was correct (i.e. did it accurately list the pharma companies with the top 3 largest R&D budgets?). Using an LLM as a judge allowed us to scalably evaluate hundreds of outputs.\\nHuman evaluation catches what automation misses.\\nPeople testing agents find edge cases that evals miss. These include hallucinated answers on unusual queries, system failures, or subtle source selection biases. In our case, human testers noticed that our early agents consistently chose SEO-optimized content farms over authoritative but less highly-ranked sources like academic PDFs or personal blogs. Adding source quality heuristics to our prompts helped resolve this issue. Even in a world of automated evaluations, manual testing remains essential.\\nMulti-agent systems have emergent behaviors, which arise without specific programming. For instance, small changes to the lead agent can unpredictably change how subagents behave. Success requires understanding interaction patterns, not just individual agent behavior. Therefore, the best prompts for these agents are not just strict instructions, but frameworks for collaboration that define the division of labor, problem-solving approaches, and effort budgets. Getting this right relies on careful prompting and tool design, solid heuristics, observability, and tight feedback loops.\\nSee the\\nopen-source prompts in our Cookbook\\nfor example prompts from our system.\\nProduction reliability and engineering challenges\\nIn traditional software, a bug might break a feature, degrade performance, or cause outages. In agentic systems, minor changes cascade into large behavioral changes, which makes it remarkably difficult to write code for complex agents that must maintain state in a long-running process.\\nAgents are stateful and errors compound.\\nAgents can run for long periods of time, maintaining state across many tool calls. This means we need to durably execute code and handle errors along the way. Without effective mitigations, minor system failures can be catastrophic for agents. When errors occur, we can't just restart from the beginning: restarts are expensive and frustrating for users. Instead, we built systems that can resume from where the agent was when the errors occurred. We also use the model’s intelligence to handle issues gracefully: for instance, letting the agent know when a tool is failing and letting it adapt works surprisingly well. We combine the adaptability of AI agents built on Claude with deterministic safeguards like retry logic and regular checkpoints.\\nDebugging benefits from new approaches.\\nAgents make dynamic decisions and are non-deterministic between runs, even with identical prompts. This makes debugging harder. For instance, users would report agents “not finding obvious information,” but we couldn't see why. Were the agents using bad search queries? Choosing poor sources? Hitting tool failures? Adding full production tracing let us diagnose why agents failed and fix issues systematically. Beyond standard observability, we monitor agent decision patterns and interaction structures—all without monitoring the contents of individual conversations, to maintain user privacy. This high-level observability helped us diagnose root causes, discover unexpected behaviors, and fix common failures.\\nDeployment needs careful coordination.\\nAgent systems are highly stateful webs of prompts, tools, and execution logic that run almost continuously. This means that whenever we deploy updates, agents might be anywhere in their process. We therefore need to prevent our well-meaning code changes from breaking existing agents. We can’t update every agent to the new version at the same time. Instead, we use\\nrainbow deployments\\nto avoid disrupting running agents, by gradually shifting traffic from old to new versions while keeping both running simultaneously.\\nSynchronous execution creates bottlenecks.\\nCurrently, our lead agents execute subagents synchronously, waiting for each set of subagents to complete before proceeding. This simplifies coordination, but creates bottlenecks in the information flow between agents. For instance, the lead agent can’t steer subagents, subagents can’t coordinate, and the entire system can be blocked while waiting for a single subagent to finish searching. Asynchronous execution would enable additional parallelism: agents working concurrently and creating new subagents when needed. But this asynchronicity adds challenges in result coordination, state consistency, and error propagation across the subagents. As models can handle longer and more complex research tasks, we expect the performance gains will justify the complexity.\\nConclusion\\nWhen building AI agents, the last mile often becomes most of the journey. Codebases that work on developer machines require significant engineering to become reliable production systems. The compound nature of errors in agentic systems means that minor issues for traditional software can derail agents entirely. One step failing can cause agents to explore entirely different trajectories, leading to unpredictable outcomes. For all the reasons described in this post, the gap between prototype and production is often wider than anticipated.\\nDespite these challenges, multi-agent systems have proven valuable for open-ended research tasks. Users have said that Claude helped them find business opportunities they hadn’t considered, navigate complex healthcare options, resolve thorny technical bugs, and save up to days of work by uncovering research connections they wouldn't have found alone. Multi-agent research systems can operate reliably at scale with careful engineering, comprehensive testing, detail-oriented prompt and tool design, robust operational practices, and tight collaboration between research, product, and engineering teams who have a strong understanding of current agent capabilities. We're already seeing these systems transform how people solve complex problems.\\nA\\nClio\\nembedding plot showing the most common ways people are using the Research feature today. The top use case categories are developing software systems across specialized domains (10%), develop and optimize professional and technical content (8%), develop business growth and revenue generation strategies (8%), assist with academic research and educational material development (7%), and research and verify information about people, places, or organizations (5%).\\nAcknowlegements\\nWritten by Jeremy Hadfield, Barry Zhang, Kenneth Lien, Florian Scholz, Jeremy Fox, and Daniel Ford. This work reflects the collective efforts of several teams across Anthropic who made the Research feature possible. Special thanks go to the Anthropic apps engineering team, whose dedication brought this complex multi-agent system to production. We're also grateful to our early users for their excellent feedback.\\nAppendix\\nBelow are some additional miscellaneous tips for multi-agent systems.\\nEnd-state evaluation of agents that mutate state over many turns.\\nEvaluating agents that modify persistent state across multi-turn conversations presents unique challenges. Unlike read-only research tasks, each action can change the environment for subsequent steps, creating dependencies that traditional evaluation methods struggle to handle. We found success focusing on end-state evaluation rather than turn-by-turn analysis. Instead of judging whether the agent followed a specific process, evaluate whether it achieved the correct final state. This approach acknowledges that agents may find alternative paths to the same goal while still ensuring they deliver the intended outcome. For complex workflows, break evaluation into discrete checkpoints where specific state changes should have occurred, rather than attempting to validate every intermediate step.\\nLong-horizon conversation management.\\nProduction agents often engage in conversations spanning hundreds of turns, requiring careful context management strategies. As conversations extend, standard context windows become insufficient, necessitating intelligent compression and memory mechanisms. We implemented patterns where agents summarize completed work phases and store essential information in external memory before proceeding to new tasks. When context limits approach, agents can spawn fresh subagents with clean contexts while maintaining continuity through careful handoffs. Further, they can retrieve stored context like the research plan from their memory rather than losing previous work when reaching the context limit. This distributed approach prevents context overflow while preserving conversation coherence across extended interactions.\\nSubagent output to a filesystem to minimize the ‘game of telephone.’\\nDirect subagent outputs can bypass the main coordinator for certain types of results, improving both fidelity and performance. Rather than requiring subagents to communicate everything through the lead agent, implement artifact systems where specialized agents can create outputs that persist independently. Subagents call tools to store their work in external systems, then pass lightweight references back to the coordinator. This prevents information loss during multi-stage processing and reduces token overhead from copying large outputs through conversation history. The pattern works particularly well for structured outputs like code, reports, or data visualizations where the subagent's specialized prompt produces better results than filtering through a general coordinator.\\nProduct\\nClaude overview\\nClaude Code\\nMax plan\\nTeam plan\\nEnterprise plan\\nDownload Claude apps\\nClaude.ai pricing plans\\nClaude.ai login\\nAPI Platform\\nAPI overview\\nDeveloper docs\\nClaude in Amazon Bedrock\\nClaude on Google Cloud's Vertex AI\\nPricing\\nConsole login\\nResearch\\nResearch overview\\nEconomic Index\\nClaude models\\nClaude Opus 4\\nClaude Sonnet 4\\nClaude Haiku 3.5\\nCommitments\\nTransparency\\nResponsible scaling policy\\nSecurity and compliance\\nSolutions\\nAI agents\\nCoding\\nCustomer support\\nEducation\\nFinancial services\\nLearn\\nAnthropic Academy\\nCustomer stories\\nEngineering at Anthropic\\nMCP Integrations\\nPartner Directory\\nExplore\\nAbout us\\nBecome a partner\\nCareers\\nEvents\\nNews\\nStartups program\\nHelp and security\\nStatus\\nAvailability\\nSupport center\\nTerms and policies\\nPrivacy choices\\nPrivacy policy\\nResponsible disclosure policy\\nTerms of service - consumer\\nTerms of service - commercial\\nUsage policy\\n© 2025 Anthropic PBC\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog = Website(\"https://www.anthropic.com/engineering/built-multi-agent-research-system?utm_source=alphasignal&utm_campaign=2025-07-18&asuniq=02f5e591\")\n",
    "user_prompt_for(blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd0d78b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyses the contents of a website     and provides a short summary, ignoring text that might be navigation related.     Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': \"You are looking at a website titled: How we built our multi-agent research system \\\\ AnthropicThe contents of this website is as follows;         please provide a short summary of this website in markdown.        if it includes news or announcements, then summarize these too. \\n\\nSkip to main content\\nSkip to footer\\nClaude\\nAPI\\nSolutions\\nResearch\\nCommitments\\nLearn\\nNews\\nTry Claude\\nEngineering at Anthropic\\nHow we built our multi-agent research system\\nPublished\\nJun 13, 2025\\nOur Research feature uses multiple Claude agents to explore complex topics more effectively. We share the engineering challenges and the lessons we learned from building this system.\\nClaude now has\\nResearch capabilities\\nthat allow it to search across the web, Google Workspace, and any integrations to accomplish complex tasks.\\nThe journey of this multi-agent system from prototype to production taught us critical lessons about system architecture, tool design, and prompt engineering. A multi-agent system consists of multiple agents (LLMs autonomously using tools in a loop) working together. Our Research feature involves an agent that plans a research process based on user queries, and then uses tools to create parallel agents that search for information simultaneously. Systems with multiple agents introduce new challenges in agent coordination, evaluation, and reliability.\\nThis post breaks down the principles that worked for us—we hope you'll find them useful to apply when building your own multi-agent systems.\\nBenefits of a multi-agent system\\nResearch work involves open-ended problems where it’s very difficult to predict the required steps in advance. You can’t hardcode a fixed path for exploring complex topics, as the process is inherently dynamic and path-dependent. When people conduct research, they tend to continuously update their approach based on discoveries, following leads that emerge during investigation.\\nThis unpredictability makes AI agents particularly well-suited for research tasks. Research demands the flexibility to pivot or explore tangential connections as the investigation unfolds. The model must operate autonomously for many turns, making decisions about which directions to pursue based on intermediate findings. A linear, one-shot pipeline cannot handle these tasks.\\nThe essence of search is compression: distilling insights from a vast corpus. Subagents facilitate compression by operating in parallel with their own context windows, exploring different aspects of the question simultaneously before condensing the most important tokens for the lead research agent. Each subagent also provides separation of concerns—distinct tools, prompts, and exploration trajectories—which reduces path dependency and enables thorough, independent investigations.\\nOnce intelligence reaches a threshold, multi-agent systems become a vital way to scale performance. For instance, although individual humans have become more intelligent in the last 100,000 years, human societies have become\\nexponentially\\nmore capable in the information age because of our\\ncollective\\nintelligence and ability to coordinate. Even generally-intelligent agents face limits when operating as individuals; groups of agents can accomplish far more.\\nOur internal evaluations show that multi-agent research systems excel especially for breadth-first queries that involve pursuing multiple independent directions simultaneously. We found that a multi-agent system with Claude Opus 4 as the lead agent and Claude Sonnet 4 subagents outperformed single-agent Claude Opus 4 by 90.2% on our internal research eval. For example, when asked to identify all the board members of the companies in the Information Technology S&P 500, the multi-agent system found the correct answers by decomposing this into tasks for subagents, while the single agent system failed to find the answer with slow, sequential searches.\\nMulti-agent systems work mainly because they help spend enough tokens to solve the problem. In our analysis, three factors explained 95% of the performance variance in the\\nBrowseComp\\nevaluation (which tests the ability of browsing agents to locate hard-to-find information). We found that token usage by itself explains 80% of the variance, with the number of tool calls and the model choice as the two other explanatory factors. This finding validates our architecture that distributes work across agents with separate context windows to add more capacity for parallel reasoning. The latest Claude models act as large efficiency multipliers on token use, as upgrading to Claude Sonnet 4 is a larger performance gain than doubling the token budget on Claude Sonnet 3.7. Multi-agent architectures effectively scale token usage for tasks that exceed the limits of single agents.\\nThere is a downside: in practice, these architectures burn through tokens fast. In our data, agents typically use about 4× more tokens than chat interactions, and multi-agent systems use about 15× more tokens than chats. For economic viability, multi-agent systems require tasks where the value of the task is high enough to pay for the increased performance. Further, some domains that require all agents to share the same context or involve many dependencies between agents are not a good fit for multi-agent systems today. For instance, most coding tasks involve fewer truly parallelizable tasks than research, and LLM agents are not yet great at coordinating and delegating to other agents in real time. We’ve found that multi-agent systems excel at valuable tasks that involve heavy parallelization, information that exceeds single context windows, and interfacing with numerous complex tools.\\nArchitecture overview for Research\\nOur Research system uses a multi-agent architecture with an orchestrator-worker pattern, where a lead agent coordinates the process while delegating to specialized subagents that operate in parallel.\\nThe multi-agent architecture in action: user queries flow through a lead agent that creates specialized subagents to search for different aspects in parallel.\\nWhen a user submits a query, the lead agent analyzes it, develops a strategy, and spawns subagents to explore different aspects simultaneously. As shown in the diagram above, the subagents act as intelligent filters by iteratively using search tools to gather information, in this case on AI agent companies in 2025, and then returning a list of companies to the lead agent so it can compile a final answer.\\nTraditional approaches using Retrieval Augmented Generation (RAG) use static retrieval. That is, they fetch some set of chunks that are most similar to an input query and use these chunks to generate a response. In contrast, our architecture uses a multi-step search that dynamically finds relevant information, adapts to new findings, and analyzes results to formulate high-quality answers.\\nProcess diagram showing the complete workflow of our multi-agent Research system. When a user submits a query, the system creates a LeadResearcher agent that enters an iterative research process. The LeadResearcher begins by thinking through the approach and saving its plan to Memory to persist the context, since if the context window exceeds 200,000 tokens it will be truncated and it is important to retain the plan. It then creates specialized Subagents (two are shown here, but it can be any number) with specific research tasks. Each Subagent independently performs web searches, evaluates tool results using\\ninterleaved thinking\\n, and returns findings to the LeadResearcher. The LeadResearcher synthesizes these results and decides whether more research is needed—if so, it can create additional subagents or refine its strategy. Once sufficient information is gathered, the system exits the research loop and passes all findings to a CitationAgent, which processes the documents and research report to identify specific locations for citations. This ensures all claims are properly attributed to their sources. The final research results, complete with citations, are then returned to the user.\\nPrompt engineering and evaluations for research agents\\nMulti-agent systems have key differences from single-agent systems, including a rapid growth in coordination complexity. Early agents made errors like spawning 50 subagents for simple queries, scouring the web endlessly for nonexistent sources, and distracting each other with excessive updates. Since each agent is steered by a prompt, prompt engineering was our primary lever for improving these behaviors. Below are some principles we learned for prompting agents:\\nThink like your agents.\\nTo iterate on prompts, you must understand their effects. To help us do this, we built simulations using our\\nConsole\\nwith the exact prompts and tools from our system, then watched agents work step-by-step. This immediately revealed failure modes: agents continuing when they already had sufficient results, using overly verbose search queries, or selecting incorrect tools. Effective prompting relies on developing an accurate mental model of the agent, which can make the most impactful changes obvious.\\nTeach the orchestrator how to delegate.\\nIn our system, the lead agent decomposes queries into subtasks and describes them to subagents. Each subagent needs an objective, an output format, guidance on the tools and sources to use, and clear task boundaries. Without detailed task descriptions, agents duplicate work, leave gaps, or fail to find necessary information. We started by allowing the lead agent to give simple, short instructions like 'research the semiconductor shortage,' but found these instructions often were vague enough that subagents misinterpreted the task or performed the exact same searches as other agents. For instance, one subagent explored the 2021 automotive chip crisis while 2 others duplicated work investigating current 2025 supply chains, without an effective division of labor.\\nScale effort to query complexity.\\nAgents struggle to judge appropriate effort for different tasks, so we embedded scaling rules in the prompts. Simple fact-finding requires just 1 agent with 3-10 tool calls, direct comparisons might need 2-4 subagents with 10-15 calls each, and complex research might use more than 10 subagents with clearly divided responsibilities. These explicit guidelines help the lead agent allocate resources efficiently and prevent overinvestment in simple queries, which was a common failure mode in our early versions.\\nTool design and selection are critical.\\nAgent-tool interfaces are as critical as human-computer interfaces. Using the right tool is efficient—often, it’s strictly necessary. For instance, an agent searching the web for context that only exists in Slack is doomed from the start. With\\nMCP servers\\nthat give the model access to external tools, this problem compounds, as agents encounter unseen tools with descriptions of wildly varying quality. We gave our agents explicit heuristics: for example, examine all available tools first, match tool usage to user intent, search the web for broad external exploration, or prefer specialized tools over generic ones. Bad tool descriptions can send agents down completely wrong paths, so each tool needs a distinct purpose and a clear description.\\nLet agents improve themselves\\n. We found that the Claude 4 models can be excellent prompt engineers. When given a prompt and a failure mode, they are able to diagnose why the agent is failing and suggest improvements. We even created a tool-testing agent—when given a flawed MCP tool, it attempts to use the tool and then rewrites the tool description to avoid failures. By testing the tool dozens of times, this agent found key nuances and bugs. This process for improving tool ergonomics resulted in a 40% decrease in task completion time for future agents using the new description, because they were able to avoid most mistakes.\\nStart wide, then narrow down.\\nSearch strategy should mirror expert human research: explore the landscape before drilling into specifics. Agents often default to overly long, specific queries that return few results. We counteracted this tendency by prompting agents to start with short, broad queries, evaluate what’s available, then progressively narrow focus.\\nGuide the thinking process.\\nExtended thinking mode\\n, which leads Claude to output additional tokens in a visible thinking process, can serve as a controllable scratchpad. The lead agent uses thinking to plan its approach, assessing which tools fit the task, determining query complexity and subagent count, and defining each subagent’s role. Our testing showed that extended thinking improved instruction-following, reasoning, and efficiency. Subagents also plan, then use\\ninterleaved thinking\\nafter tool results to evaluate quality, identify gaps, and refine their next query. This makes subagents more effective in adapting to any task.\\nParallel tool calling transforms speed and performance.\\nComplex research tasks naturally involve exploring many sources. Our early agents executed sequential searches, which was painfully slow. For speed, we introduced two kinds of parallelization: (1) the lead agent spins up 3-5 subagents in parallel rather than serially; (2) the subagents use 3+ tools in parallel. These changes cut research time by up to 90% for complex queries, allowing Research to do more work in minutes instead of hours while covering more information than other systems.\\nOur prompting strategy focuses on instilling good heuristics rather than rigid rules. We studied how skilled humans approach research tasks and encoded these strategies in our prompts—strategies like decomposing difficult questions into smaller tasks, carefully evaluating the quality of sources, adjusting search approaches based on new information, and recognizing when to focus on depth (investigating one topic in detail) vs. breadth (exploring many topics in parallel). We also proactively mitigated unintended side effects by setting explicit guardrails to prevent the agents from spiraling out of control. Finally, we focused on a fast iteration loop with observability and test cases.\\nEffective evaluation of agents\\nGood evaluations are essential for building reliable AI applications, and agents are no different. However, evaluating multi-agent systems presents unique challenges. Traditional evaluations often assume that the AI follows the same steps each time: given input X, the system should follow path Y to produce output Z. But multi-agent systems don't work this way. Even with identical starting points, agents might take completely different valid paths to reach their goal. One agent might search three sources while another searches ten, or they might use different tools to find the same answer. Because we don’t always know what the right steps are, we usually can't just check if agents followed the “correct” steps we prescribed in advance. Instead, we need flexible evaluation methods that judge whether agents achieved the right outcomes while also following a reasonable process.\\nStart evaluating immediately with small samples\\n. In early agent development, changes tend to have dramatic impacts because there is abundant low-hanging fruit. A prompt tweak might boost success rates from 30% to 80%. With effect sizes this large, you can spot changes with just a few test cases. We started with a set of about 20 queries representing real usage patterns. Testing these queries often allowed us to clearly see the impact of changes. We often hear that AI developer teams delay creating evals because they believe that only large evals with hundreds of test cases are useful. However, it’s best to start with small-scale testing right away with a few examples, rather than delaying until you can build more thorough evals.\\nLLM-as-judge evaluation scales when done well.\\nResearch outputs are difficult to evaluate programmatically, since they are free-form text and rarely have a single correct answer. LLMs are a natural fit for grading outputs. We used an LLM judge that evaluated each output against criteria in a rubric: factual accuracy (do claims match sources?), citation accuracy (do the cited sources match the claims?), completeness (are all requested aspects covered?), source quality (did it use primary sources over lower-quality secondary sources?), and tool efficiency (did it use the right tools a reasonable number of times?). We experimented with multiple judges to evaluate each component, but found that a single LLM call with a single prompt outputting scores from 0.0-1.0 and a pass-fail grade was the most consistent and aligned with human judgements. This method was especially effective when the eval test cases\\ndid\\nhave a clear answer, and we could use the LLM judge to simply check if the answer was correct (i.e. did it accurately list the pharma companies with the top 3 largest R&D budgets?). Using an LLM as a judge allowed us to scalably evaluate hundreds of outputs.\\nHuman evaluation catches what automation misses.\\nPeople testing agents find edge cases that evals miss. These include hallucinated answers on unusual queries, system failures, or subtle source selection biases. In our case, human testers noticed that our early agents consistently chose SEO-optimized content farms over authoritative but less highly-ranked sources like academic PDFs or personal blogs. Adding source quality heuristics to our prompts helped resolve this issue. Even in a world of automated evaluations, manual testing remains essential.\\nMulti-agent systems have emergent behaviors, which arise without specific programming. For instance, small changes to the lead agent can unpredictably change how subagents behave. Success requires understanding interaction patterns, not just individual agent behavior. Therefore, the best prompts for these agents are not just strict instructions, but frameworks for collaboration that define the division of labor, problem-solving approaches, and effort budgets. Getting this right relies on careful prompting and tool design, solid heuristics, observability, and tight feedback loops.\\nSee the\\nopen-source prompts in our Cookbook\\nfor example prompts from our system.\\nProduction reliability and engineering challenges\\nIn traditional software, a bug might break a feature, degrade performance, or cause outages. In agentic systems, minor changes cascade into large behavioral changes, which makes it remarkably difficult to write code for complex agents that must maintain state in a long-running process.\\nAgents are stateful and errors compound.\\nAgents can run for long periods of time, maintaining state across many tool calls. This means we need to durably execute code and handle errors along the way. Without effective mitigations, minor system failures can be catastrophic for agents. When errors occur, we can't just restart from the beginning: restarts are expensive and frustrating for users. Instead, we built systems that can resume from where the agent was when the errors occurred. We also use the model’s intelligence to handle issues gracefully: for instance, letting the agent know when a tool is failing and letting it adapt works surprisingly well. We combine the adaptability of AI agents built on Claude with deterministic safeguards like retry logic and regular checkpoints.\\nDebugging benefits from new approaches.\\nAgents make dynamic decisions and are non-deterministic between runs, even with identical prompts. This makes debugging harder. For instance, users would report agents “not finding obvious information,” but we couldn't see why. Were the agents using bad search queries? Choosing poor sources? Hitting tool failures? Adding full production tracing let us diagnose why agents failed and fix issues systematically. Beyond standard observability, we monitor agent decision patterns and interaction structures—all without monitoring the contents of individual conversations, to maintain user privacy. This high-level observability helped us diagnose root causes, discover unexpected behaviors, and fix common failures.\\nDeployment needs careful coordination.\\nAgent systems are highly stateful webs of prompts, tools, and execution logic that run almost continuously. This means that whenever we deploy updates, agents might be anywhere in their process. We therefore need to prevent our well-meaning code changes from breaking existing agents. We can’t update every agent to the new version at the same time. Instead, we use\\nrainbow deployments\\nto avoid disrupting running agents, by gradually shifting traffic from old to new versions while keeping both running simultaneously.\\nSynchronous execution creates bottlenecks.\\nCurrently, our lead agents execute subagents synchronously, waiting for each set of subagents to complete before proceeding. This simplifies coordination, but creates bottlenecks in the information flow between agents. For instance, the lead agent can’t steer subagents, subagents can’t coordinate, and the entire system can be blocked while waiting for a single subagent to finish searching. Asynchronous execution would enable additional parallelism: agents working concurrently and creating new subagents when needed. But this asynchronicity adds challenges in result coordination, state consistency, and error propagation across the subagents. As models can handle longer and more complex research tasks, we expect the performance gains will justify the complexity.\\nConclusion\\nWhen building AI agents, the last mile often becomes most of the journey. Codebases that work on developer machines require significant engineering to become reliable production systems. The compound nature of errors in agentic systems means that minor issues for traditional software can derail agents entirely. One step failing can cause agents to explore entirely different trajectories, leading to unpredictable outcomes. For all the reasons described in this post, the gap between prototype and production is often wider than anticipated.\\nDespite these challenges, multi-agent systems have proven valuable for open-ended research tasks. Users have said that Claude helped them find business opportunities they hadn’t considered, navigate complex healthcare options, resolve thorny technical bugs, and save up to days of work by uncovering research connections they wouldn't have found alone. Multi-agent research systems can operate reliably at scale with careful engineering, comprehensive testing, detail-oriented prompt and tool design, robust operational practices, and tight collaboration between research, product, and engineering teams who have a strong understanding of current agent capabilities. We're already seeing these systems transform how people solve complex problems.\\nA\\nClio\\nembedding plot showing the most common ways people are using the Research feature today. The top use case categories are developing software systems across specialized domains (10%), develop and optimize professional and technical content (8%), develop business growth and revenue generation strategies (8%), assist with academic research and educational material development (7%), and research and verify information about people, places, or organizations (5%).\\nAcknowlegements\\nWritten by Jeremy Hadfield, Barry Zhang, Kenneth Lien, Florian Scholz, Jeremy Fox, and Daniel Ford. This work reflects the collective efforts of several teams across Anthropic who made the Research feature possible. Special thanks go to the Anthropic apps engineering team, whose dedication brought this complex multi-agent system to production. We're also grateful to our early users for their excellent feedback.\\nAppendix\\nBelow are some additional miscellaneous tips for multi-agent systems.\\nEnd-state evaluation of agents that mutate state over many turns.\\nEvaluating agents that modify persistent state across multi-turn conversations presents unique challenges. Unlike read-only research tasks, each action can change the environment for subsequent steps, creating dependencies that traditional evaluation methods struggle to handle. We found success focusing on end-state evaluation rather than turn-by-turn analysis. Instead of judging whether the agent followed a specific process, evaluate whether it achieved the correct final state. This approach acknowledges that agents may find alternative paths to the same goal while still ensuring they deliver the intended outcome. For complex workflows, break evaluation into discrete checkpoints where specific state changes should have occurred, rather than attempting to validate every intermediate step.\\nLong-horizon conversation management.\\nProduction agents often engage in conversations spanning hundreds of turns, requiring careful context management strategies. As conversations extend, standard context windows become insufficient, necessitating intelligent compression and memory mechanisms. We implemented patterns where agents summarize completed work phases and store essential information in external memory before proceeding to new tasks. When context limits approach, agents can spawn fresh subagents with clean contexts while maintaining continuity through careful handoffs. Further, they can retrieve stored context like the research plan from their memory rather than losing previous work when reaching the context limit. This distributed approach prevents context overflow while preserving conversation coherence across extended interactions.\\nSubagent output to a filesystem to minimize the ‘game of telephone.’\\nDirect subagent outputs can bypass the main coordinator for certain types of results, improving both fidelity and performance. Rather than requiring subagents to communicate everything through the lead agent, implement artifact systems where specialized agents can create outputs that persist independently. Subagents call tools to store their work in external systems, then pass lightweight references back to the coordinator. This prevents information loss during multi-stage processing and reduces token overhead from copying large outputs through conversation history. The pattern works particularly well for structured outputs like code, reports, or data visualizations where the subagent's specialized prompt produces better results than filtering through a general coordinator.\\nProduct\\nClaude overview\\nClaude Code\\nMax plan\\nTeam plan\\nEnterprise plan\\nDownload Claude apps\\nClaude.ai pricing plans\\nClaude.ai login\\nAPI Platform\\nAPI overview\\nDeveloper docs\\nClaude in Amazon Bedrock\\nClaude on Google Cloud's Vertex AI\\nPricing\\nConsole login\\nResearch\\nResearch overview\\nEconomic Index\\nClaude models\\nClaude Opus 4\\nClaude Sonnet 4\\nClaude Haiku 3.5\\nCommitments\\nTransparency\\nResponsible scaling policy\\nSecurity and compliance\\nSolutions\\nAI agents\\nCoding\\nCustomer support\\nEducation\\nFinancial services\\nLearn\\nAnthropic Academy\\nCustomer stories\\nEngineering at Anthropic\\nMCP Integrations\\nPartner Directory\\nExplore\\nAbout us\\nBecome a partner\\nCareers\\nEvents\\nNews\\nStartups program\\nHelp and security\\nStatus\\nAvailability\\nSupport center\\nTerms and policies\\nPrivacy choices\\nPrivacy policy\\nResponsible disclosure policy\\nTerms of service - consumer\\nTerms of service - commercial\\nUsage policy\\n© 2025 Anthropic PBC\"}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def messages_for(website):\n",
    "    return[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "messages_for(blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d10b8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of \"How We Built Our Multi-Agent Research System\"\n",
       "\n",
       "The article details the engineering journey of developing a multi-agent research system using multiple Claude language models (LLMs) to tackle complex research tasks more efficiently. This system allows the lead agent to orchestrate several subagents that operate concurrently, which increases performance, especially for dynamic and unpredictable research queries.\n",
       "\n",
       "## Key Highlights\n",
       "\n",
       "- **Multi-Agent System Overview**: The system employs a lead agent that plans the research process and spawns various subagents to work in parallel, improving problem-solving capabilities by allowing broader exploration without being path-dependent.\n",
       "\n",
       "- **Research Efficiency**: Internal evaluations showed that the multi-agent system significantly outperformed single-agent setups, particularly in tasks requiring extensive information retrieval.\n",
       "\n",
       "- **Token Usage and Performance**: A multi-agent system utilizes token calls more effectively, substantially improving efficiency in complex queries, although it requires managing higher token costs for economic feasibility.\n",
       "\n",
       "- **Architecture Description**: The architecture involves an orchestrator-worker model, where the lead agent creates subagents for specific tasks, showcasing a dynamic approach to information gathering compared to traditional static methods.\n",
       "\n",
       "- **Prompt Engineering**: Essential principles for effective prompting were discussed, emphasizing the importance of clear delegation and task separation for achieving optimal performance from the agents.\n",
       "\n",
       "- **Production Challenges**: The article explores various challenges faced in deploying and maintaining such systems, including error handling, state management, and the coordination of asynchronous operations.\n",
       "\n",
       "- **Human Evaluation**: While automated evaluations assist in measuring performance, human testers play a critical role in identifying edge cases and potential biases in agent behavior.\n",
       "\n",
       "## Usage Insights\n",
       "\n",
       "Anthropic's research feature is utilized across various domains, such as software development, content optimization, business strategy, and academic research, reflecting its versatility in handling complex, open-ended tasks.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The engineering process highlighted the gap between prototype and production, emphasizing the extensive work needed to create reliable multi-agent systems capable of significant problem-solving in research contexts. Regular feedback loops and collaborative efforts are central to refining these systems for scaling and reliability.\n",
       "\n",
       "This article was published on June 13, 2025, and reflects contributions from multiple team members at Anthropic."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = 'gpt-4o-mini',\n",
    "        messages=messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def dispaly_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))\n",
    "\n",
    "dispaly_summary(\"https://www.anthropic.com/engineering/built-multi-agent-research-system?utm_source=alphasignal&utm_campaign=2025-07-18&asuniq=02f5e591\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b45481",
   "metadata": {},
   "source": [
    "### selenium web scapping for sites which use js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2b1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs chrome webdriver (https://sites.google.com/chromium.org/driver/)\n",
    "import undetected_chromedriver as uc\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By # select elements\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "# service = Service(executable_path=\"./chromedriver\")\n",
    "# driver = webdriver.Chrome(service=service) \n",
    "\n",
    "driver = uc.Chrome(headless=False)\n",
    "\n",
    "driver.get(\"https://openai.com/index/introducing-chatgpt-agent/\")\n",
    "time.sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a908cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from openai import OpenAI\n",
    "\n",
    "class BRK_Scaper:\n",
    "    def __init__(self, url, model_provider, model_version=\"deepseek-r1:8b\", ):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using BeautifulSoupe Library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.driver = uc.Chrome(headless=False)\n",
    "        self.model_version = model_version\n",
    "        self.model_provider = model_provider\n",
    "\n",
    "    def get_page(self):\n",
    "        self.driver.get(self.url)\n",
    "        html = self.driver.page_source\n",
    "        self.driver.quit()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelavent in soup.body([\"script\", \"style\", \"img\", \"input\", \"nav\", \"style\", ]):\n",
    "            irrelavent.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        # self.soup = soup (for debugging or selectively retaining page contents)\n",
    "\n",
    "    \n",
    "        \n",
    "    def get_summary(self):\n",
    "        \n",
    "        if self.model_provider=='ollama':\n",
    "            llm = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "        elif self.model_provider=='openai':\n",
    "            llm = OpenAI()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model provider: {self.model_provider}\")\n",
    "\n",
    "        self.system_prompt = \"You are an assistant that analyses the contents of a website \\\n",
    "            and provides a short summary, ignoring text that might be navigation related. \\\n",
    "            Respond in markdown.\"\n",
    "        \n",
    "        self.human_prompt = f\"You are looking at a website titled: {self.title} \\\n",
    "            please provide a short summary of this website in markdown.\\\n",
    "            if it includes news or announcements, then summarize these too. \\n\\n \\\n",
    "            {self.text}\" \n",
    "\n",
    "        response = llm.chat.completions.create(\n",
    "            model=self.model_version,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": self.human_prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.summary = response.choices[0].message.content\n",
    "        display(Markdown(self.summary))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28a4fa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of \"Introducing ChatGPT agent: bridging research and action | OpenAI\"\n",
       "\n",
       "On July 17, 2025, OpenAI announced the launch of the **ChatGPT agent**, a new feature that enhances ChatGPT's capabilities to think and act proactively, utilizing its own computer to perform complex tasks. Users can now delegate tasks such as analyzing calendars, planning meals, or creating presentations, with ChatGPT intelligently navigating the web and handling workflows autonomously. \n",
       "\n",
       "### Key Features:\n",
       "- **Unified Agentic System**: Combines strengths from previous models (Operator for web interaction and deep research for information synthesis) to perform tasks efficiently.\n",
       "- **Tool Suite**: Includes a visual browser and text-based browser for web interactions, terminal access, and API integration.\n",
       "- **Iterative Workflows**: Users can interrupt tasks and provide additional directions as needed, allowing for a more collaborative experience.\n",
       "- **Real-World Utility**: Useful for both personal and professional tasks, such as scheduling appointments, planning travel, or automating reports.\n",
       "- **Safety Measures**: Enhanced controls for data privacy and task confirmations to reduce risks associated with accessing live web data.\n",
       "\n",
       "### Performance Highlights:\n",
       "- Achieved a state-of-the-art performance on various evaluation benchmarks, such as completing complex real-world tasks and improving on previous models.\n",
       "  \n",
       "### Availability:\n",
       "The ChatGPT agent starts rolling out to Pro, Plus, and Team users, with access expanding to other user tiers in the coming weeks.\n",
       "\n",
       "### Risks and Controls:\n",
       "OpenAI outlined potential risks, particularly regarding data usage and web interactions, implementing action confirmations and user oversight to mitigate these concerns. \n",
       "\n",
       "### Future Enhancements:\n",
       "OpenAI plans to continuously improve the ChatGPT agent's functionality, expanding its capabilities while ensuring user safety.\n",
       "\n",
       "This launch marks the beginning of an evolving interaction model, where users can expect enhanced intelligence and automation in handling tasks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://openai.com/index/introducing-chatgpt-agent/\"\n",
    "scrapper = BRK_Scaper(url=url, model_provider='openai', model_version=\"gpt-4o-mini\")\n",
    "scrapper.get_page()\n",
    "scrapper.get_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
